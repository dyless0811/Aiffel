{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 10:00:14.572855: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-07-23 10:00:14.572953: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 10:00:15.124851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-23 10:00:15.125096: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-07-23 10:00:15.234120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.4906 - accuracy: 0.8804\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2338 - accuracy: 0.9337\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1849 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1557 - accuracy: 0.9552\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1355 - accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1201 - accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1080 - accuracy: 0.9694\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0974 - accuracy: 0.9717\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0883 - accuracy: 0.9751\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0808 - accuracy: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 10:01:50.560972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1091 - accuracy: 0.9684\n",
      "test_loss: 0.10905203223228455 \n",
      "test_accuracy: 0.9684000611305237\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22dedca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91ca32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "370b6235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58205931,  0.04551326, -0.49486035, -1.24607984,  0.55335383,\n",
       "       -1.43058759,  0.47446024,  1.14802849,  0.46425613,  1.61989731,\n",
       "       -1.20702241, -0.10510935,  1.14059931, -0.59995111,  1.64364685,\n",
       "        1.58223094,  1.80569403,  0.17278563,  0.50814824, -0.7554197 ,\n",
       "       -0.84365853,  0.35564361,  0.20171975,  1.08959124,  0.34168312,\n",
       "       -0.3506312 ,  0.21768778,  1.75960041, -0.79483223,  0.29825145,\n",
       "        0.67166858,  0.64535844, -0.14783461,  0.07427627,  0.00408056,\n",
       "       -0.33332487,  0.78347323,  0.59021497, -1.9273904 , -0.76164203,\n",
       "       -1.51750555,  0.177876  ,  0.10493663,  0.81419395, -0.14250029,\n",
       "        0.35131884,  0.21909258, -0.17389325, -0.4199727 ,  0.79392825])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cba3ab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64154112 0.51137635 0.37874926 0.22337948 0.63491335 0.19300715\n",
      " 0.61643889 0.75915063 0.61402336 0.83478097 0.23022832 0.47374683\n",
      " 0.75778966 0.35435488 0.83803055 0.82952024 0.85884065 0.54308926\n",
      " 0.62437228 0.31964152 0.30076481 0.58798547 0.55025963 0.74830474\n",
      " 0.58459932 0.41322937 0.55420805 0.85315961 0.31113204 0.57401501\n",
      " 0.66187668 0.65596374 0.46310851 0.51856054 0.50102014 0.41743185\n",
      " 0.68642819 0.64341447 0.1270397  0.31828987 0.17982913 0.54435212\n",
      " 0.52621011 0.69300249 0.46443509 0.58693736 0.55455509 0.45663591\n",
      " 0.39652328 0.68867418]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af86229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "871a6652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07665407  0.18348117 -0.16239049 -0.05045492 -0.27293644  0.12623493\n",
      "  0.98149438  0.19822547  0.22364095  0.24666303]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12b511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281ba50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08710021, 0.09692005, 0.06858095, 0.07670373, 0.06140362,\n",
       "       0.09152757, 0.21527142, 0.09835966, 0.10089155, 0.10324123])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23925fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a633e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08710021 0.09692005 0.06858095 0.07670373 0.06140362 0.09152757\n",
      " 0.21527142 0.09835966 0.10089155 0.10324123]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d92124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3813158290303207"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe1860e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01742004,  0.01938401,  0.01371619,  0.01534075,  0.01228072,\n",
       "        -0.18169449,  0.04305428,  0.01967193,  0.02017831,  0.02064825],\n",
       "       [-0.17963695,  0.01990001,  0.0154225 ,  0.01931266,  0.01709166,\n",
       "         0.01690983,  0.03518589,  0.01615556,  0.01967457,  0.0199843 ],\n",
       "       [ 0.02375853,  0.02151285,  0.01303741,  0.01966324, -0.1836551 ,\n",
       "         0.0205427 ,  0.03009203,  0.0183117 ,  0.022164  ,  0.01457266],\n",
       "       [ 0.01991048, -0.18238578,  0.01436757,  0.01622321,  0.01374217,\n",
       "         0.01803103,  0.0382781 ,  0.01774806,  0.02321718,  0.02086799],\n",
       "       [ 0.02082168,  0.0195159 ,  0.01492588,  0.01703127,  0.01929096,\n",
       "         0.01764525,  0.03272891,  0.01898733,  0.01893791, -0.17988509]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "경사하강법\n",
    "'''\n",
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b4de097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05547989, -0.08690575,  0.03579109,  0.04381382, -0.05703792,\n",
       "        -0.03459024,  0.08972725,  0.04504527,  0.05266144, -0.03302507],\n",
       "       [-0.0807711 , -0.10997398,  0.04840065,  0.05874406, -0.05404059,\n",
       "        -0.05083335,  0.1211521 ,  0.06068833,  0.07041865, -0.06378477],\n",
       "       [-0.05622346, -0.08443002,  0.03787026,  0.04614903, -0.05361352,\n",
       "        -0.05338122,  0.09570127,  0.04785656,  0.05556886, -0.03549776],\n",
       "       [-0.0570634 , -0.05992984,  0.04409613,  0.05324655, -0.04341875,\n",
       "        -0.07057571,  0.11044607,  0.0559114 ,  0.06333984, -0.09605229],\n",
       "       [ 0.00714687, -0.08506666,  0.02573455,  0.03136672, -0.05356046,\n",
       "        -0.03319431,  0.06565917,  0.03334239,  0.03888485, -0.03031311],\n",
       "       [-0.03402175, -0.03045204,  0.02466507,  0.03029682, -0.04362259,\n",
       "        -0.02755867,  0.06110193,  0.03127456,  0.0357543 , -0.04743764],\n",
       "       [-0.04370329, -0.07396723,  0.0279142 ,  0.03401165, -0.0406575 ,\n",
       "        -0.05397402,  0.07192107,  0.03537575,  0.04147244,  0.00160693],\n",
       "       [-0.07519561, -0.1059834 ,  0.04464455,  0.05322428, -0.00829856,\n",
       "        -0.03066345,  0.11042562,  0.05542639,  0.06364458, -0.10722441],\n",
       "       [-0.0611748 , -0.08947735,  0.03463348,  0.04280839, -0.07004063,\n",
       "        -0.03282222,  0.08716066,  0.0435599 ,  0.05150899, -0.00615643],\n",
       "       [-0.06436928, -0.07091097,  0.04128623,  0.05005501, -0.04958816,\n",
       "        -0.10136235,  0.1063766 ,  0.05258481,  0.06039279, -0.02446467],\n",
       "       [-0.05299256, -0.02472978,  0.02029349,  0.02635877, -0.08399464,\n",
       "         0.00813423,  0.0488842 ,  0.02535594,  0.03038774,  0.00230261],\n",
       "       [-0.06671519, -0.07107898,  0.04560385,  0.05565575, -0.06521538,\n",
       "        -0.05096024,  0.11333978,  0.05758829,  0.06601767, -0.08423555],\n",
       "       [-0.07069573, -0.0443706 ,  0.02718972,  0.03327482, -0.03193886,\n",
       "        -0.02692756,  0.06753692,  0.03369488,  0.03916181, -0.0269254 ],\n",
       "       [-0.06872546, -0.10169059,  0.05898091,  0.07147491, -0.07325497,\n",
       "        -0.1014267 ,  0.14902106,  0.07506234,  0.08577401, -0.09521551],\n",
       "       [-0.07465426, -0.07603735,  0.051358  ,  0.06301575, -0.0883912 ,\n",
       "        -0.06744179,  0.12831153,  0.06511075,  0.07481767, -0.07608909],\n",
       "       [-0.02284601, -0.03171763,  0.03325537,  0.0420565 , -0.11755131,\n",
       "        -0.04882093,  0.08328187,  0.04321378,  0.04983605, -0.0307077 ],\n",
       "       [-0.00374126, -0.05221528,  0.02898506,  0.03616496, -0.08594219,\n",
       "        -0.01071156,  0.07106522,  0.03738587,  0.04312603, -0.06411684],\n",
       "       [-0.06979056, -0.03043238,  0.02726284,  0.03368559, -0.04460588,\n",
       "        -0.02358165,  0.06714033,  0.03391037,  0.03924541, -0.03283408],\n",
       "       [-0.01609301, -0.03704666,  0.01921336,  0.02292733, -0.00949053,\n",
       "        -0.01296708,  0.0471781 ,  0.02420716,  0.02735137, -0.06528003],\n",
       "       [-0.0507573 , -0.00821734,  0.02676365,  0.03357499, -0.0690039 ,\n",
       "        -0.01659203,  0.06489516,  0.03379587,  0.0386447 , -0.0531038 ],\n",
       "       [ 0.00031624, -0.02124159,  0.02527414,  0.03092238, -0.05760882,\n",
       "        -0.09680339,  0.06667761,  0.03355796,  0.03768876, -0.0187833 ],\n",
       "       [-0.0019621 , -0.02800193,  0.03246996,  0.04050429, -0.10058774,\n",
       "        -0.07178583,  0.08252519,  0.04270555,  0.04850027, -0.04436767],\n",
       "       [-0.07387715, -0.07286555,  0.03117143,  0.03924068, -0.08424223,\n",
       "        -0.01351284,  0.07746978,  0.03889777,  0.04657311,  0.01114501],\n",
       "       [-0.08765731, -0.05925135,  0.02944747,  0.03598127, -0.03021927,\n",
       "        -0.04060385,  0.07429664,  0.0363597 ,  0.04271119, -0.00106448],\n",
       "       [-0.02258265, -0.04056091,  0.03468502,  0.04152692, -0.02996598,\n",
       "        -0.09086789,  0.08878748,  0.04474372,  0.05001548, -0.0757812 ],\n",
       "       [-0.05461933, -0.06991441,  0.03013889,  0.03678421, -0.03722368,\n",
       "         0.00529572,  0.07313231,  0.03732955,  0.04349214, -0.06441539],\n",
       "       [-0.05571726, -0.03714344,  0.03585868,  0.04355804, -0.04688725,\n",
       "        -0.10624907,  0.09279691,  0.04597742,  0.05221718, -0.02441121],\n",
       "       [-0.10041902, -0.06848172,  0.04480773,  0.05502109, -0.06501253,\n",
       "        -0.03859358,  0.11078877,  0.05585978,  0.06470566, -0.05867616],\n",
       "       [-0.06039888, -0.06871721,  0.05565428,  0.06811863, -0.09916056,\n",
       "        -0.1169172 ,  0.14136137,  0.0714684 ,  0.08143092, -0.07283976],\n",
       "       [-0.06470151, -0.07004455,  0.04375036,  0.05406228, -0.09172757,\n",
       "        -0.06391329,  0.11007873,  0.0556413 ,  0.06442413, -0.03756988],\n",
       "       [-0.00700806, -0.08551665,  0.04244095,  0.0506676 , -0.03634627,\n",
       "        -0.07503856,  0.10735479,  0.05460359,  0.06157296, -0.11273036],\n",
       "       [-0.04849004, -0.05421546,  0.04406077,  0.0532723 , -0.04809077,\n",
       "        -0.06307154,  0.10967325,  0.05598702,  0.0631884 , -0.11231392],\n",
       "       [-0.07837813, -0.04609083,  0.04730726,  0.05667625, -0.02399888,\n",
       "        -0.10715091,  0.11981103,  0.05989598,  0.06728067, -0.09535244],\n",
       "       [-0.02807332, -0.05506935,  0.02751669,  0.03381005, -0.056026  ,\n",
       "        -0.05442923,  0.07044282,  0.03532928,  0.04092818, -0.01442913],\n",
       "       [-0.06123674, -0.07940674,  0.03427964,  0.04138134, -0.03393104,\n",
       "        -0.10119921,  0.09010776,  0.04359773,  0.05065881,  0.01574846],\n",
       "       [ 0.00213113, -0.05565236,  0.02700657,  0.03350214, -0.07814375,\n",
       "        -0.04966205,  0.0689953 ,  0.03533813,  0.0408275 , -0.02434262],\n",
       "       [-0.10203922, -0.08086701,  0.03697513,  0.04507297, -0.03649057,\n",
       "        -0.04931038,  0.09333367,  0.04574542,  0.05372135, -0.00614137],\n",
       "       [-0.10258498, -0.0612482 ,  0.04195283,  0.05103222, -0.03645905,\n",
       "        -0.02379557,  0.1026313 ,  0.05181829,  0.05964222, -0.08298906],\n",
       "       [-0.02094343, -0.05207464,  0.02933441,  0.03686125, -0.09731419,\n",
       "        -0.06695309,  0.07578109,  0.03825112,  0.04467829,  0.0123792 ],\n",
       "       [-0.07751746, -0.07713528,  0.05213427,  0.06383044, -0.08264483,\n",
       "        -0.06068033,  0.12967882,  0.06591905,  0.07563816, -0.08922283],\n",
       "       [-0.06404317, -0.08404206,  0.04353771,  0.05316207, -0.06771917,\n",
       "        -0.08445172,  0.11115307,  0.05537262,  0.06405551, -0.02702486],\n",
       "       [-0.05884167, -0.07666038,  0.03517729,  0.04320539, -0.05641399,\n",
       "         0.00342503,  0.08547232,  0.04380811,  0.05105538, -0.07022748],\n",
       "       [-0.03971616, -0.01407496,  0.02361415,  0.02860056, -0.0223424 ,\n",
       "        -0.03479789,  0.05838838,  0.02979079,  0.03341753, -0.06287998],\n",
       "       [-0.01656785, -0.06061175,  0.05038636,  0.06192859, -0.11484297,\n",
       "        -0.12052915,  0.12890572,  0.06574426,  0.07460615, -0.06901936],\n",
       "       [-0.09048694, -0.03860717,  0.03397439,  0.04163492, -0.04572611,\n",
       "        -0.08759194,  0.08742597,  0.04276111,  0.04941831,  0.00719747],\n",
       "       [-0.03400259, -0.07978866,  0.0249721 ,  0.03060769, -0.04379517,\n",
       "        -0.0205723 ,  0.06302905,  0.0314517 ,  0.03727366, -0.0091755 ],\n",
       "       [ 0.01290644, -0.080209  ,  0.03012056,  0.03704641, -0.07772833,\n",
       "        -0.04665367,  0.07683092,  0.03937001,  0.04558384, -0.03726717],\n",
       "       [-0.08937037, -0.06852174,  0.03413391,  0.04128034, -0.01950124,\n",
       "        -0.02725818,  0.08458556,  0.0420094 ,  0.04879008, -0.04614776],\n",
       "       [-0.00451355, -0.09170578,  0.02502445,  0.02990927, -0.02521224,\n",
       "        -0.04432392,  0.06473917,  0.03210775,  0.03741342, -0.02343857],\n",
       "       [-0.05114226, -0.02731181,  0.03658309,  0.04408813, -0.0340887 ,\n",
       "        -0.10335014,  0.09380978,  0.04686371,  0.05255114, -0.05800294]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0921ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e0e6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fa58d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbb63e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터를 업데이트하는 함수\n",
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "552e554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "오차역전파법\n",
    "'''\n",
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0eb410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23096111 0.08926441 0.05682361 0.05002748 0.0686314  0.21097563\n",
      "  0.07400901 0.08423817 0.05304904 0.08202014]\n",
      " [0.21029547 0.09518633 0.05600391 0.04935998 0.0682373  0.22700421\n",
      "  0.05939161 0.0947923  0.0550722  0.08465669]\n",
      " [0.18589278 0.08602904 0.0482602  0.05535509 0.07095098 0.23182548\n",
      "  0.08024979 0.0979526  0.05366186 0.08982217]\n",
      " [0.18034763 0.10710158 0.05691056 0.06632518 0.06830778 0.20096195\n",
      "  0.06442691 0.10248088 0.05659329 0.09654424]\n",
      " [0.21623967 0.08146966 0.05379617 0.05976969 0.07811718 0.20523702\n",
      "  0.07188835 0.08184586 0.05441119 0.09722521]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.0651446407195797\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "모델 학습 Step-by-Step\n",
    "'''\n",
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3ce3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_ont_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffc5053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.09283317 0.17938668 0.0942933  0.04369707 0.03054785 0.06774566\n",
      "  0.08436713 0.1793807  0.03032019 0.19742825]\n",
      " [0.12795625 0.14856437 0.10748518 0.06108304 0.03474451 0.06704314\n",
      "  0.09294293 0.16565492 0.03254551 0.16198016]\n",
      " [0.11391077 0.16257678 0.09366585 0.05094903 0.0345828  0.06277188\n",
      "  0.09558523 0.18232167 0.03300984 0.17062616]\n",
      " [0.12113106 0.15779197 0.09461613 0.06126691 0.02745252 0.05287895\n",
      "  0.09776041 0.18082499 0.03766277 0.16861428]\n",
      " [0.11810527 0.15567734 0.09603288 0.05257993 0.04037617 0.05656043\n",
      "  0.09139171 0.16682151 0.02916042 0.19329434]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.3204959261951834\n",
      "---------\n",
      "[[0.10816406 0.19218685 0.08164725 0.04112389 0.04060001 0.09054631\n",
      "  0.07381345 0.13581282 0.02946345 0.20664191]\n",
      " [0.15553219 0.15833431 0.0927646  0.05727494 0.04528469 0.0846845\n",
      "  0.08092319 0.12529573 0.03148389 0.16842195]\n",
      " [0.13149021 0.17323006 0.08262648 0.04813967 0.04768915 0.07991041\n",
      "  0.084854   0.14128476 0.03240996 0.1783653 ]\n",
      " [0.1399537  0.17728881 0.08255393 0.05766192 0.03563788 0.06726179\n",
      "  0.08568586 0.13878102 0.03645805 0.17871705]\n",
      " [0.13533125 0.16735383 0.08241156 0.04893808 0.05212103 0.07115684\n",
      "  0.07857058 0.12612976 0.02804712 0.20993995]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.119351336744163\n",
      "---------\n",
      "[[0.11916427 0.19712689 0.07074729 0.03794674 0.051471   0.11466292\n",
      "  0.0645246  0.1082724  0.02794871 0.20813519]\n",
      " [0.17905805 0.16183572 0.08007708 0.05269918 0.05645221 0.10153796\n",
      "  0.07034829 0.09949659 0.02975545 0.16873947]\n",
      " [0.14413928 0.17730408 0.07293738 0.04471335 0.06302123 0.09669905\n",
      "  0.07523582 0.11473329 0.03117163 0.18004489]\n",
      " [0.1535133  0.19121967 0.07205134 0.05335603 0.04441969 0.08148001\n",
      "  0.07503388 0.11168659 0.03456774 0.18267176]\n",
      " [0.14730338 0.17281893 0.07085172 0.04481341 0.06462658 0.0853487\n",
      "  0.06758312 0.1001828  0.02643127 0.22004011]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9636730707523178\n",
      "---------\n",
      "[[0.12644401 0.19751586 0.06163626 0.03469969 0.0628769  0.13909469\n",
      "  0.05663108 0.08917078 0.02616034 0.2057704 ]\n",
      " [0.19886273 0.16181226 0.06951535 0.04811023 0.06799147 0.11686534\n",
      "  0.06140144 0.08153021 0.02778001 0.16613097]\n",
      " [0.15255335 0.17752473 0.06470026 0.04120458 0.08047659 0.11232274\n",
      "  0.06693519 0.09596955 0.0296374  0.17867561]\n",
      " [0.16264824 0.20182993 0.06324375 0.0490434  0.05362356 0.09493561\n",
      "  0.06601331 0.09270079 0.03243656 0.18352486]\n",
      " [0.15493969 0.17471404 0.06131845 0.04078105 0.07764499 0.09852755\n",
      "  0.05845251 0.08215526 0.02465273 0.22681373]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.8382971609125662\n",
      "---------\n",
      "[[0.13078049 0.19543556 0.05404191 0.03160447 0.07437644 0.1627543\n",
      "  0.04996167 0.07510422 0.02429667 0.20164427]\n",
      " [0.21562409 0.15997311 0.0607765  0.0438116  0.07949992 0.13000936\n",
      "  0.05389986 0.0683155  0.02576897 0.16232109]\n",
      " [0.15758031 0.175581   0.0577106  0.03783094 0.09969936 0.1260205\n",
      "  0.05981175 0.08191546 0.02798104 0.17586903]\n",
      " [0.16830275 0.21060669 0.05589284 0.0449863  0.06293073 0.10701772\n",
      "  0.0584276  0.07863825 0.03027263 0.1829245 ]\n",
      " [0.15923402 0.1746757  0.05346803 0.03704889 0.09072636 0.11009091\n",
      "  0.05089089 0.06890629 0.02287036 0.23208855]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.7347455085707992\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de8231dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "추론 과정 구현과 정확도(Accuracy) 계산\n",
    "'''\n",
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c00db8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13299462, 0.1921921 , 0.04770097, 0.02876078, 0.08547816,\n",
       "       0.1848205 , 0.0443306 , 0.06433583, 0.02247363, 0.19691281])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c119f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa5d2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13299462 0.1921921  0.04770097 0.02876078 0.08547816 0.1848205\n",
      " 0.0443306  0.06433583 0.02247363 0.19691281]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_one_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "110a21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "전체 학습 사이클 수행\n",
    "'''\n",
    "# 학습시키는 파라미터 초기화하는 함수\n",
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c602024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.2993903061860212\n",
      "train acc, test acc | 0.1561, 0.1576\n",
      "Loss:  0.8359993408706857\n",
      "train acc, test acc | 0.7835333333333333, 0.7902\n",
      "Loss:  0.5415375405526841\n",
      "train acc, test acc | 0.8783666666666666, 0.8821\n",
      "Loss:  0.4077779026972382\n",
      "train acc, test acc | 0.8967, 0.9008\n",
      "Loss:  0.4365387936568182\n",
      "train acc, test acc | 0.9075, 0.9084\n",
      "Loss:  0.18857525581182258\n",
      "train acc, test acc | 0.9151, 0.9177\n",
      "Loss:  0.3000361496677754\n",
      "train acc, test acc | 0.9198166666666666, 0.9232\n",
      "Loss:  0.20440939400338215\n",
      "train acc, test acc | 0.9242333333333334, 0.9265\n",
      "Loss:  0.19285016753102863\n",
      "train acc, test acc | 0.9286666666666666, 0.9299\n",
      "Loss:  0.21128538809692834\n",
      "train acc, test acc | 0.93195, 0.9348\n",
      "Loss:  0.2246974072401164\n",
      "train acc, test acc | 0.93385, 0.935\n",
      "Loss:  0.21655342714031206\n",
      "train acc, test acc | 0.9369166666666666, 0.9379\n",
      "Loss:  0.14068216649553636\n",
      "train acc, test acc | 0.9399166666666666, 0.9409\n",
      "Loss:  0.21848044411446074\n",
      "train acc, test acc | 0.9417333333333333, 0.9414\n",
      "Loss:  0.14393732998337477\n",
      "train acc, test acc | 0.9444, 0.9443\n",
      "Loss:  0.1666566362321158\n",
      "train acc, test acc | 0.9459666666666666, 0.9455\n",
      "Loss:  0.1971886423538158\n",
      "train acc, test acc | 0.94755, 0.947\n",
      "Loss:  0.13572254385261476\n",
      "train acc, test acc | 0.9495833333333333, 0.9489\n",
      "Loss:  0.20112766210035296\n",
      "train acc, test acc | 0.9504833333333333, 0.9501\n",
      "Loss:  0.17489058124784343\n",
      "train acc, test acc | 0.9522333333333334, 0.9514\n",
      "Loss:  0.19794162951492564\n",
      "train acc, test acc | 0.9531, 0.9524\n",
      "Loss:  0.128661135992239\n",
      "train acc, test acc | 0.9549666666666666, 0.9543\n",
      "Loss:  0.19734706253910797\n",
      "train acc, test acc | 0.9560833333333333, 0.9541\n",
      "Loss:  0.2597137222570336\n",
      "train acc, test acc | 0.9564666666666667, 0.9544\n",
      "Loss:  0.09407053391316465\n",
      "train acc, test acc | 0.9577833333333333, 0.9553\n",
      "Loss:  0.15262219265674618\n",
      "train acc, test acc | 0.9590333333333333, 0.9562\n",
      "Loss:  0.1343922655242561\n",
      "train acc, test acc | 0.9603, 0.957\n",
      "Loss:  0.13268178482003734\n",
      "train acc, test acc | 0.9610166666666666, 0.9581\n",
      "Loss:  0.1229325524813923\n",
      "train acc, test acc | 0.96175, 0.9571\n",
      "Loss:  0.05971108421646551\n",
      "train acc, test acc | 0.9630166666666666, 0.9596\n",
      "Loss:  0.23282211074243747\n",
      "train acc, test acc | 0.9634333333333334, 0.96\n",
      "Loss:  0.10466331628791742\n",
      "train acc, test acc | 0.96435, 0.9603\n",
      "Loss:  0.07299504311341792\n",
      "train acc, test acc | 0.9649166666666666, 0.9603\n",
      "Loss:  0.18206401105247694\n",
      "train acc, test acc | 0.9656833333333333, 0.9614\n",
      "Loss:  0.12098300018254513\n",
      "train acc, test acc | 0.9663333333333334, 0.9618\n",
      "Loss:  0.18039686687609854\n",
      "train acc, test acc | 0.9672666666666667, 0.9622\n",
      "Loss:  0.1038150177980971\n",
      "train acc, test acc | 0.9679833333333333, 0.9626\n",
      "Loss:  0.09659936672516421\n",
      "train acc, test acc | 0.9682333333333333, 0.9626\n",
      "Loss:  0.10374179110270837\n",
      "train acc, test acc | 0.9686166666666667, 0.9641\n",
      "Loss:  0.21440718759645766\n",
      "train acc, test acc | 0.9693666666666667, 0.9635\n",
      "Loss:  0.11895463702825947\n",
      "train acc, test acc | 0.9700833333333333, 0.9646\n",
      "Loss:  0.08116924215001126\n",
      "train acc, test acc | 0.9704166666666667, 0.9637\n",
      "Loss:  0.07719526318220317\n",
      "train acc, test acc | 0.9705333333333334, 0.9644\n",
      "Loss:  0.10815707031634987\n",
      "train acc, test acc | 0.9715333333333334, 0.965\n",
      "Loss:  0.12642732990562816\n",
      "train acc, test acc | 0.9721166666666666, 0.9659\n",
      "Loss:  0.17070609910055257\n",
      "train acc, test acc | 0.9723166666666667, 0.9668\n",
      "Loss:  0.04962629264796309\n",
      "train acc, test acc | 0.9729, 0.9651\n",
      "Loss:  0.1124154667239463\n",
      "train acc, test acc | 0.9734833333333334, 0.9655\n",
      "Loss:  0.13571283980190837\n",
      "train acc, test acc | 0.97375, 0.967\n",
      "Loss:  0.10759518851653939\n",
      "train acc, test acc | 0.9742, 0.9668\n",
      "Loss:  0.09534184926678846\n",
      "train acc, test acc | 0.9742166666666666, 0.9666\n",
      "Loss:  0.10404745209744411\n",
      "train acc, test acc | 0.97475, 0.9668\n",
      "Loss:  0.06802018970629721\n",
      "train acc, test acc | 0.9752833333333333, 0.9674\n",
      "Loss:  0.10715916521780254\n",
      "train acc, test acc | 0.9752333333333333, 0.9682\n",
      "Loss:  0.09844656958930678\n",
      "train acc, test acc | 0.9759, 0.9689\n",
      "Loss:  0.0599781680496034\n",
      "train acc, test acc | 0.9763666666666667, 0.9684\n",
      "Loss:  0.04683350394489603\n",
      "train acc, test acc | 0.97655, 0.9691\n",
      "Loss:  0.0747947472809025\n",
      "train acc, test acc | 0.9769666666666666, 0.9689\n",
      "Loss:  0.07112161242412848\n",
      "train acc, test acc | 0.9770666666666666, 0.9689\n",
      "Loss:  0.07082932569981631\n",
      "train acc, test acc | 0.9774833333333334, 0.9693\n",
      "Loss:  0.09786379481104328\n",
      "train acc, test acc | 0.9779333333333333, 0.9697\n",
      "Loss:  0.09154156532615422\n",
      "train acc, test acc | 0.97815, 0.9688\n",
      "Loss:  0.09100708050242448\n",
      "train acc, test acc | 0.9781333333333333, 0.9697\n",
      "Loss:  0.06362822495931604\n",
      "train acc, test acc | 0.9785166666666667, 0.9697\n",
      "Loss:  0.09244171651077066\n",
      "train acc, test acc | 0.9792166666666666, 0.9709\n",
      "Loss:  0.07982296726590186\n",
      "train acc, test acc | 0.9790166666666666, 0.9715\n",
      "Loss:  0.04953656111627245\n",
      "train acc, test acc | 0.9792, 0.9707\n",
      "Loss:  0.05627303390175355\n",
      "train acc, test acc | 0.9794666666666667, 0.9703\n",
      "Loss:  0.045367816579171084\n",
      "train acc, test acc | 0.9799333333333333, 0.9704\n",
      "Loss:  0.09933904624601389\n",
      "train acc, test acc | 0.9798333333333333, 0.9717\n",
      "Loss:  0.06904932300514419\n",
      "train acc, test acc | 0.9805, 0.9711\n",
      "Loss:  0.07291978253420034\n",
      "train acc, test acc | 0.9802666666666666, 0.9707\n",
      "Loss:  0.04508069538346564\n",
      "train acc, test acc | 0.98115, 0.9719\n",
      "Loss:  0.07139104490662539\n",
      "train acc, test acc | 0.98155, 0.9718\n",
      "Loss:  0.049588810715285675\n",
      "train acc, test acc | 0.9813, 0.9717\n",
      "Loss:  0.06986652816813033\n",
      "train acc, test acc | 0.9816833333333334, 0.9724\n",
      "Loss:  0.162547396301624\n",
      "train acc, test acc | 0.9816, 0.9717\n",
      "Loss:  0.06414182702781406\n",
      "train acc, test acc | 0.9819666666666667, 0.9714\n",
      "Loss:  0.06941326973442616\n",
      "train acc, test acc | 0.9817833333333333, 0.9718\n",
      "Loss:  0.026638266540690438\n",
      "train acc, test acc | 0.9819166666666667, 0.9714\n",
      "Loss:  0.08427800491328899\n",
      "train acc, test acc | 0.9824833333333334, 0.9723\n",
      "Loss:  0.025958237646632198\n",
      "train acc, test acc | 0.98265, 0.9723\n",
      "Loss:  0.05069065772739528\n",
      "train acc, test acc | 0.9830666666666666, 0.9732\n",
      "Loss:  0.0632800027256733\n",
      "train acc, test acc | 0.98295, 0.9735\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ea811fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "훈련 과정 Accuracy, Loss 변화를 시각화\n",
    "'''\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ce6ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ho",
   "language": "python",
   "name": "ho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
